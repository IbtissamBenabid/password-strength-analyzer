{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 21:28:20,963 - INFO - Project root directory: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\n",
      "2025-05-17 21:28:20,964 - INFO - Attempting to load: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_very_weak.csv\n",
      "2025-05-17 21:28:20,972 - INFO - Loaded 5000 passwords from c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_very_weak.csv\n",
      "2025-05-17 21:28:20,973 - INFO - Attempting to load: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_weak.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 21:28:20,979 - INFO - Loaded 5000 passwords from c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_weak.csv\n",
      "2025-05-17 21:28:20,980 - INFO - Attempting to load: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_average.csv\n",
      "2025-05-17 21:28:20,987 - INFO - Loaded 5000 passwords from c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_average.csv\n",
      "2025-05-17 21:28:20,988 - INFO - Attempting to load: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_strong.csv\n",
      "2025-05-17 21:28:20,996 - INFO - Loaded 5000 passwords from c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_strong.csv\n",
      "2025-05-17 21:28:20,996 - INFO - Attempting to load: c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_very_strong.csv\n",
      "2025-05-17 21:28:21,005 - INFO - Loaded 5000 passwords from c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\data\\raw\\pwlds_very_strong.csv\n",
      "2025-05-17 21:28:21,007 - INFO - Total dataset size: 25000 passwords\n",
      "2025-05-17 21:28:21,629 - INFO - Extracted features for 25000 passwords\n",
      "2025-05-17 21:28:21,637 - INFO - Training set size: 20000\n",
      "2025-05-17 21:28:21,638 - INFO - Test set size: 5000\n",
      "2025-05-17 21:28:30,027 - INFO - Best parameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "2025-05-17 21:28:30,224 - INFO - Model saved successfully to c:\\Users\\hp\\Desktop\\AI\\SYSMDP\\models\\password_strength_model.joblib\n",
      "2025-05-17 21:28:30,226 - INFO - Password analysis completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     average       0.84      0.94      0.89       985\n",
      "      strong       0.92      0.81      0.86       989\n",
      " very_strong       1.00      1.00      1.00      1005\n",
      "   very_weak       1.00      1.00      1.00      1021\n",
      "        weak       0.94      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.94      0.94      0.94      5000\n",
      "weighted avg       0.94      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_project_root():\n",
    "    \"\"\"Get the project root directory.\"\"\"\n",
    "    try:\n",
    "        # Try to get the directory containing the script\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        # If we're in the notebooks directory, go up one level\n",
    "        if os.path.basename(script_dir) == 'notebooks':\n",
    "            return os.path.dirname(script_dir)\n",
    "        return script_dir\n",
    "    except NameError:\n",
    "        # If running in notebook, use current directory\n",
    "        current_dir = os.getcwd()\n",
    "        # If we're in the notebooks directory, go up one level\n",
    "        if os.path.basename(current_dir) == 'notebooks':\n",
    "            return os.path.dirname(current_dir)\n",
    "        return current_dir\n",
    "\n",
    "def calculate_entropy(password):\n",
    "    \"\"\"Calculate Shannon entropy of a password.\"\"\"\n",
    "    if not password:\n",
    "        return 0.0\n",
    "    \n",
    "    freq = {}\n",
    "    for char in password:\n",
    "        freq[char] = freq.get(char, 0) + 1\n",
    "    \n",
    "    entropy = 0\n",
    "    for count in freq.values():\n",
    "        probability = count / len(password)\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def extract_features(password):\n",
    "    \"\"\"Extract features from a password.\"\"\"\n",
    "    features = {\n",
    "        'length': len(password),\n",
    "        'lowercase': sum(1 for c in password if c.islower()),\n",
    "        'uppercase': sum(1 for c in password if c.isupper()),\n",
    "        'digits': sum(1 for c in password if c.isdigit()),\n",
    "        'special': sum(1 for c in password if not c.isalnum()),\n",
    "        'entropy': calculate_entropy(password)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def load_and_process_data():\n",
    "    \"\"\"Load and process all password datasets.\"\"\"\n",
    "    # Get the project root directory\n",
    "    project_root = get_project_root()\n",
    "    logger.info(f\"Project root directory: {project_root}\")\n",
    "    \n",
    "    # Load all datasets\n",
    "    datasets = {\n",
    "        'very_weak': os.path.join(project_root, 'data', 'raw', 'pwlds_very_weak.csv'),\n",
    "        'weak': os.path.join(project_root, 'data', 'raw', 'pwlds_weak.csv'),\n",
    "        'average': os.path.join(project_root, 'data', 'raw', 'pwlds_average.csv'),\n",
    "        'strong': os.path.join(project_root, 'data', 'raw', 'pwlds_strong.csv'),\n",
    "        'very_strong': os.path.join(project_root, 'data', 'raw', 'pwlds_very_strong.csv')\n",
    "    }\n",
    "    \n",
    "    all_data = []\n",
    "    for strength, file_path in datasets.items():\n",
    "        try:\n",
    "            logger.info(f\"Attempting to load: {file_path}\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Rename columns to match our expected format\n",
    "                df = df.rename(columns={'Password': 'password', 'Strength_Level': 'strength_level'})\n",
    "                df['strength'] = strength\n",
    "                all_data.append(df)\n",
    "                logger.info(f\"Loaded {len(df)} passwords from {file_path}\")\n",
    "            else:\n",
    "                logger.error(f\"File does not exist: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {file_path}: {str(e)}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        logger.error(\"No datasets were loaded successfully\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all datasets\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    logger.info(f\"Total dataset size: {len(df)} passwords\")\n",
    "    \n",
    "    # Extract features\n",
    "    features_list = []\n",
    "    for password in df['password']:\n",
    "        features = extract_features(password)\n",
    "        features_list.append(features)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    features_df['strength'] = df['strength']\n",
    "    \n",
    "    logger.info(f\"Extracted features for {len(features_df)} passwords\")\n",
    "    return features_df\n",
    "\n",
    "def train_model(features_df):\n",
    "    \"\"\"Train the password strength model.\"\"\"\n",
    "    # Prepare data for training\n",
    "    X = features_df.drop('strength', axis=1)\n",
    "    y = features_df['strength']\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    logger.info(f\"Training set size: {len(X_train)}\")\n",
    "    logger.info(f\"Test set size: {len(X_test)}\")\n",
    "    \n",
    "    # Define parameter grid (reduced for faster training)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    \n",
    "    # Create and train model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters\n",
    "    logger.info(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def save_model(model):\n",
    "    \"\"\"Save the trained model.\"\"\"\n",
    "    # Get the project root directory\n",
    "    project_root = get_project_root()\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    models_dir = os.path.join(project_root, 'models')\n",
    "    Path(models_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(models_dir, 'password_strength_model.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "    logger.info(f\"Model saved successfully to {model_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the password analysis pipeline.\"\"\"\n",
    "    try:\n",
    "        # Load and process data\n",
    "        features_df = load_and_process_data()\n",
    "        if features_df is None:\n",
    "            return\n",
    "        \n",
    "        # Train model\n",
    "        model = train_model(features_df)\n",
    "        \n",
    "        # Save model\n",
    "        save_model(model)\n",
    "        \n",
    "        logger.info(\"Password analysis completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main pipeline: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
